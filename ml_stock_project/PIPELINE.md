# Pipeline Notes

## End-to-End Steps
1. `src/data_io.py`
   - Load market data from CSV / Parquet / SQLite.
   - Standardize to `date, stock, open, high, low, close, volume`.
2. `src/cleaning.py`
   - Remove duplicates and invalid rows.
   - Drop each stock's first 60 sessions.
   - Compute `prev_close`, `ret_1`.
3. `src/features.py`
   - Build momentum, MA deviation, volatility, volume, RSI, MACD, ATR.
   - Build industry-aware features:
     - `industry_code` (low-memory categorical encoding)
     - `sector_strength_rank` from daily equal-weight industry return.
   - Clip extreme values.
   - Convert to cross-sectional rank features by date (`rk_*`).
   - Build `future_return_5d` and binary label.
4. `src/split.py`
   - Split strictly by calendar date from `config.py`.
5. `src/train.py`
   - Train `LGBMClassifier` with early stopping on validation AUC.
6. `src/backtest.py`
   - Event-driven simulation:
     - Signal day `t-1`, trade at `t` open.
     - Filter limit-up at open.
     - Enforce `max_per_sector` hard cap if industry is available.
     - Hold each tranche for fixed `hold_days`.
     - Aggregate daily portfolio return with tranche capital weighting.
7. `src/evaluation.py`
   - Q1~Q5 quintile analysis.
   - Yearly performance from strategy daily return series.
   - TopK hit rate and concentration diagnostics.

## No-Leakage Rules
- All rolling features are generated per stock in chronological order.
- Labels are generated by forward shift (`shift(-5)`), never used in feature creation.
- Backtest execution uses next-day trading after signal generation.

## Recommended Workflow
1. Validate data integrity and date coverage.
2. Run full pipeline with `python main.py`.
3. First check diagnostics:
   - `quintile_cumulative.png`
   - `yearly_returns.csv`
   - `daily_topk_hit_rate.csv`
4. Then optimize model and risk controls iteratively.
